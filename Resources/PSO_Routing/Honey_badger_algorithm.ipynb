{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOuTR3LEN_n8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import copy\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
        "import math\n",
        "import pickle\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from scipy.stats import qmc\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dCwNpgUOJlk",
        "outputId": "efe68de1-7e78-4d13-9c25-c289c7dc9514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(datetime.now().timestamp())"
      ],
      "metadata": {
        "id": "Mv4CmlsTOLLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/MyDrive/Networks/test_cases.zip -d /"
      ],
      "metadata": {
        "id": "1WKmOOl9ONdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_nodes =  [20,25,30,35,40,45,50,55,60]\n",
        "test_case_num = 30\n",
        "\n",
        "#defining network parameters\n",
        "GATEWAY_ID = 0\n",
        "spread_factor = range(7,13)"
      ],
      "metadata": {
        "id": "4gtjPN40OPOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population_size = 30\n",
        "max_iterations = 500\n",
        "large_positive_value = 10**6\n",
        "large_negative_value = -10**6\n",
        "init_priority = [-1000, 1000]\n",
        "decrease_param = 2\n",
        "beta_param = 6\n",
        "C = 0.5\n",
        "alpha = 1\n",
        "beta = 2\n"
      ],
      "metadata": {
        "id": "RG8dpBX-OSbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Honey_badger:\n",
        "  def __init__(self, position, fitness):\n",
        "    self.pos = position\n",
        "    self.fitness = fitness\n",
        "  \n",
        "  def __str__(self):\n",
        "    return f'''\n",
        "            position = {self.position}\\n\n",
        "            fitness = {self.fitness}\\n\n",
        "            '''"
      ],
      "metadata": {
        "id": "r8XMr7ePOrBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(path, isGraph):\n",
        "  if isGraph:\n",
        "    G = nx.read_gml(path,destringizer=int)\n",
        "    return G\n",
        "  with open(path,'rb') as file:\n",
        "    data = pickle.load(file)\n",
        "    file.close()\n",
        "    return data"
      ],
      "metadata": {
        "id": "r-mvFXvQPH29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_path(G, position, edge_nodes):\n",
        "  N_DEVICES = len(G.nodes)\n",
        "  ans = {}\n",
        "  for f in edge_nodes:\n",
        "    iteration = 0\n",
        "    visited_nodes = [False for u in range(N_DEVICES)]\n",
        "    start = {(f,k): position[f,k] for k in spread_factor}\n",
        "    terminal_node, sf = max(start, key = lambda x: start[x])\n",
        "    path = []\n",
        "    while terminal_node != GATEWAY_ID and iteration <= N_DEVICES:\n",
        "      visited_nodes[terminal_node] = True\n",
        "      adj_nodes = {}\n",
        "      for v in G.adj[terminal_node]:\n",
        "        if visited_nodes[v]:\n",
        "          continue\n",
        "        for k in spread_factor:\n",
        "          adj_nodes[(v,k)] = position[v,k]\n",
        "      if len(adj_nodes) == 0:\n",
        "        break\n",
        "      next_node, next_sf = max(adj_nodes, key = lambda x: adj_nodes[x])\n",
        "      path.append((terminal_node, next_node, sf))\n",
        "      terminal_node = next_node\n",
        "      sf = next_sf\n",
        "      iteration = iteration + 1\n",
        "    ans[f] = path\n",
        "  return ans"
      ],
      "metadata": {
        "id": "WxhxuGRFPMNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fitness(honey_badger, iteration, edge_nodes, G, network_data):\n",
        "  fitness_cost = 0\n",
        "  path = decode_path(G, honey_badger.pos, edge_nodes)\n",
        "  for f in edge_nodes:\n",
        "    #adding a penalty if invalid path is returned\n",
        "    if path[f][-1][1] != GATEWAY_ID:\n",
        "      fitness_cost = fitness_cost + large_positive_value\n",
        "      continue\n",
        "\n",
        "    #Calculate cost of path and adding link capacity penalty\n",
        "    total_delay = 0\n",
        "    for i,j,k in path[f]:\n",
        "      fitness_cost = fitness_cost + network_data['cst'][f,i,j,k]\n",
        "      if network_data['max_edge_data_rate'][k]-network_data['data_rate'][f,i,j,k] < 0:\n",
        "        fitness_cost = fitness_cost + network_data['cst'][f,i,j,k] + ((C*iteration)**alpha)*((network_data['max_edge_data_rate'][k]-network_data['data_rate'][f,i,j,k])**beta) \n",
        "      total_delay = total_delay + network_data['edge_delays'][f,i,j] + network_data['tx_time'][k] + network_data['eh_time'][i,k]      \n",
        "\n",
        "    #Adding delay constraint penalty\n",
        "    if network_data['max_flow_delays'][f]-total_delay < 0:\n",
        "      fitness_cost = fitness_cost + ((C*iteration)**alpha)*((network_data['max_flow_delays'][f]-total_delay)**beta)\n",
        "\n",
        "  honey_badger.fitness = fitness_cost"
      ],
      "metadata": {
        "id": "T5JWjVPuPOL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Honey_badger_algorithm(edge_nodes, G, network_data):\n",
        "  start = time.time()\n",
        "  end = time.time()\n",
        "  converge_iter = 0\n",
        "  N_DEVICES = len(G.nodes)\n",
        "\n",
        "\n",
        "  decreasing_factor = decrease_param\n",
        "\n",
        "  #Population initialization\n",
        "  population = [Honey_badger(\n",
        "      {(u,k) : init_priority[0] + random.random()*(init_priority[1]-init_priority[0]) for u in range(N_DEVICES) for k in spread_factor},\n",
        "      0\n",
        "  ) for c in range(population_size)]\n",
        "\n",
        "  #evaluate fitness of each honey badger position\n",
        "  for p in range(population_size):\n",
        "    calculate_fitness(population[p], 0, edge_nodes, G, network_data)\n",
        "\n",
        "  #initialize prey\n",
        "  prey = copy.deepcopy(population[0])\n",
        "  for p in range(population_size):\n",
        "    if prey.fitness > population[p].fitness:\n",
        "      prey = copy.deepcopy(population[p])\n",
        "\n",
        "  for iter in range(1,max_iterations+1):\n",
        "\n",
        "    #update the decreasing factor.\n",
        "    decreasing_factor = decrease_param*((math.e)**(-iter/max_iterations))\n",
        "\n",
        "    for p in range(population_size):\n",
        "\n",
        "      #calculate intensity\n",
        "      d = 0\n",
        "      for i in range(N_DEVICES):\n",
        "        for j in spread_factor:\n",
        "          d = d + (prey.pos[i,j]-population[p].pos[i,j])\n",
        "      \n",
        "      S = 0\n",
        "      for i in range(N_DEVICES):\n",
        "        for j in spread_factor:\n",
        "          S = S + (population[p].pos[i,j]-population[(p+1)%population_size].pos[i,j])**2\n",
        "      \n",
        "      intensity = 0\n",
        "      if d != 0:\n",
        "        intensity = random.random()*(S/(4*math.pi*(d**2)))\n",
        "\n",
        "      #altering search direction\n",
        "      F = -1\n",
        "      if random.random() <= 0.5:\n",
        "        F = 1\n",
        "      \n",
        "      new_position = copy.deepcopy(population[p])\n",
        "\n",
        "      if random.random() < 0.5:\n",
        "        #update position\n",
        "        for i in range(N_DEVICES):\n",
        "          for j in spread_factor:\n",
        "            r3,r4,r5 = np.random.uniform(low = 0, high = 1, size = 3).tolist()\n",
        "            new_position.pos[i,j] = prey.pos[i,j] + F*beta_param*intensity*prey.pos[i,j] + F*r3*decreasing_factor*d*abs(math.cos(2*math.pi*r4)*abs(1-math.cos(2*math.pi*r5)))\n",
        "      else:\n",
        "        #update position\n",
        "        for i in range(N_DEVICES):\n",
        "          for j in spread_factor:\n",
        "            new_position.pos[i,j] = prey.pos[i,j] + F*random.random()*decreasing_factor*d\n",
        "\n",
        "      \n",
        "      #evaluate position\n",
        "      calculate_fitness(new_position, iter, edge_nodes, G, network_data)\n",
        "\n",
        "      if new_position.fitness <= population[p].fitness:\n",
        "        population[p] = copy.deepcopy(new_position)\n",
        "      \n",
        "      if new_position.fitness <= prey.fitness:\n",
        "        prey = copy.deepcopy(new_position)\n",
        "        converge_iter = iter\n",
        "        end = time.time()\n",
        "\n",
        "  #decode solution\n",
        "  ans = decode_path(G, prey.pos, edge_nodes)\n",
        "  return [prey.fitness, ans, converge_iter, (end-start)]\n",
        "      "
      ],
      "metadata": {
        "id": "kbJay5xJPsV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expected_ans = read_data(\"/content/gdrive/MyDrive/Networks/expected_ans.pkl\", False)"
      ],
      "metadata": {
        "id": "LYP0kxLj5Yd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "route_optimality_ratio = {}\n",
        "near_route_optimality_ratio = {}\n",
        "route_failure_ratio = {}\n",
        "near_route_failure_ratio = {}\n",
        "results = {}\n",
        "percent_gap = {}\n",
        "iterations_to_converge = {}\n",
        "time_to_converge = {}\n",
        "invalid_tests = {}\n",
        "for N_DEVICES in num_of_nodes:\n",
        "  correct_solution = 0\n",
        "  nearly_correct = 0\n",
        "  total_tests = 0\n",
        "  invalid_graph = 0\n",
        "  results[N_DEVICES] = []\n",
        "  percent_gap[N_DEVICES] = []\n",
        "  iterations_to_converge[N_DEVICES] = []\n",
        "  time_to_converge[N_DEVICES] = []\n",
        "  for t in range(1,test_case_num+1):\n",
        "\n",
        "    #reading data\n",
        "    network_data = {}\n",
        "    G = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/graph.gml\",True)\n",
        "    network_data['tx_time'] = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/tx_time.txt\", False)\n",
        "    network_data['max_edge_data_rate'] = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/max_edge_data_rate.txt\",False)\n",
        "    network_data['cst'] = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/cst.txt\",False)\n",
        "    network_data['max_flow_delays'] = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/max_flow_delays.txt\",False)\n",
        "    network_data['edge_delays'] = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/edge_delays.txt\",False)\n",
        "    network_data['max_edge_delays'] = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/max_edge_delays.txt\",False)\n",
        "    network_data['data_rate'] = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/data_rate.txt\",False)\n",
        "    network_data['eh_time'] = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/eh_time.txt\",False)\n",
        "    network_data['init_res_energy'] = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/init_res_energy.txt\",False)\n",
        "    edge_nodes = read_data(f\"test_cases/num_nodes_{N_DEVICES}/test_{t}/edge_nodes.txt\",False)\n",
        "\n",
        "\n",
        "    #Get 2D coordinates of all the devices\n",
        "    coordinates = {i:G.nodes()[i]['pos'] for i in G.nodes}\n",
        "\n",
        "    #creating a list of bidirectional edges\n",
        "    edge_list = []\n",
        "    for u,v in G.edges:\n",
        "      edge_list.append((u,v))\n",
        "      edge_list.append((v,u))\n",
        "    if expected_ans[N_DEVICES][t] == -1:\n",
        "      invalid_graph = invalid_graph + 1\n",
        "      continue\n",
        "    optimal_cost, optimal_path, converge_iter, converge_time = Honey_badger_algorithm(edge_nodes, G, network_data)\n",
        "    optimal_cost = round(optimal_cost, 2)\n",
        "    print(f\"num_nodes = {N_DEVICES}, test_case = {t}, actual_cost = {optimal_cost}, optimal_cost = {expected_ans[N_DEVICES][t]}\")\n",
        "\n",
        "    time_to_converge[N_DEVICES].append(converge_time)\n",
        "    iterations_to_converge[N_DEVICES].append(converge_iter)\n",
        "    results[N_DEVICES].append([optimal_cost,expected_ans[N_DEVICES][t]])\n",
        "    percent_gap[N_DEVICES].append(((optimal_cost-expected_ans[N_DEVICES][t])/expected_ans[N_DEVICES][t])*100)\n",
        "    total_tests = total_tests + 1\n",
        "    if ((optimal_cost-expected_ans[N_DEVICES][t])/expected_ans[N_DEVICES][t])*100 <= 4:\n",
        "      nearly_correct = nearly_correct + 1\n",
        "    if optimal_cost == expected_ans[N_DEVICES][t]:\n",
        "      correct_solution = correct_solution + 1\n",
        "  \n",
        "  #calculating route optimality ratio\n",
        "  if total_tests == 0:\n",
        "    continue\n",
        "  invalid_tests[N_DEVICES] = invalid_graph\n",
        "  near_route_optimality_ratio[N_DEVICES] = nearly_correct/total_tests\n",
        "  near_route_failure_ratio[N_DEVICES] = (total_tests-nearly_correct)/total_tests\n",
        "  route_optimality_ratio[N_DEVICES] = correct_solution/total_tests\n",
        "  route_failure_ratio[N_DEVICES] = (total_tests-correct_solution)/total_tests"
      ],
      "metadata": {
        "id": "mf6Bwsjc5arr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving results\n",
        "def save_file(file_name, results):\n",
        "  with open(\"/content/gdrive/MyDrive/Networks/\" + file_name, 'wb') as file:\n",
        "    pickle.dump(results, file)\n",
        "    file.close"
      ],
      "metadata": {
        "id": "BC9jmv7-5h3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_file(\"HBA_route_optimality_ratio.pkl\", route_optimality_ratio)\n",
        "save_file(\"HBA_route_failure_ratio.pkl\", route_failure_ratio)\n",
        "save_file(\"HBA_results.pkl\", results)\n",
        "save_file(\"HBA_percent_gap.pkl\", percent_gap)\n",
        "save_file(\"HBA_iterations_to_converge.pkl\", iterations_to_converge)\n",
        "save_file(\"HBA_time_to_converge.pkl\", time_to_converge)"
      ],
      "metadata": {
        "id": "_4nLKK-85kLQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}