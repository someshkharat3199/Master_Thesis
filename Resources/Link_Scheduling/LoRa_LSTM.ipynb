{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#import necessary python libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import tensorflow as tf\n",
        "mpl.rcParams['figure.figsize'] = (10,8)\n",
        "mpl.rcParams['axes.grid'] = False"
      ],
      "metadata": {
        "id": "3DzXPaBUQ1zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_path):\n",
        "  dataset = pd.read_csv(data_path, header = 0, sep = ' ',\n",
        "            names = ['x','y','dev1/dev2','orient','tx_pwr','col','rssi_1','rssi_2','rssi_3','rssi_4','rssi_5'])\n",
        "  dataset.set_index(['x','y'])\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "EtwDoUWrQ-Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = load_data(\"/content/omni_variable_txpower.txt\")"
      ],
      "metadata": {
        "id": "7fY2TNEARy2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = data_set.groupby(['x','y'])"
      ],
      "metadata": {
        "id": "Vmau2WIkS73x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "locations = set()\n",
        "for i in zip(data_set['x'],data_set['y']):\n",
        "  locations.add(i)"
      ],
      "metadata": {
        "id": "y5vhRyuJUURE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_sets = []\n",
        "for k in list(locations)[:2]:\n",
        "  data_sets.append(grouped.get_group(k))\n"
      ],
      "metadata": {
        "id": "jRuy19vkT6SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rssi1 = data_sets[0]['rssi_1']\n",
        "rssi2 = data_sets[0]['rssi_2']\n",
        "rssi3 = data_sets[0]['rssi_3']\n",
        "rssi4 = data_sets[0]['rssi_4']\n",
        "rssi5 = data_sets[0]['rssi_5']\n",
        "rssi6 = data_sets[1]['rssi_1']\n",
        "rssi7 = data_sets[1]['rssi_2']\n",
        "rssi8 = data_sets[1]['rssi_3']\n",
        "rssi9 = data_sets[1]['rssi_4']\n",
        "rssi10 = data_sets[1]['rssi_5']\n",
        "rssi11 = data_sets[1]['rssi_1']"
      ],
      "metadata": {
        "id": "SGJinyhRYPBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rssi1.plot(grid=True)\n",
        "rssi2.plot(grid=True)\n",
        "rssi3.plot(grid=True)\n",
        "rssi4.plot(grid=True)\n",
        "rssi5.plot(grid=True)\n",
        "rssi6.plot(grid=True)\n",
        "rssi7.plot(grid=True)\n",
        "rssi8.plot(grid=True)\n",
        "rssi9.plot(grid=True)\n",
        "rssi10.plot(grid=True)\n",
        "rssi11.plot(grid=True)"
      ],
      "metadata": {
        "id": "OqX06nkSZfJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_input = [data_sets[0][['tx_pwr','rssi_1']],\n",
        "data_sets[0][['tx_pwr','rssi_2']],\n",
        "data_sets[0][['tx_pwr','rssi_3']],\n",
        "data_sets[0][['tx_pwr','rssi_4']],\n",
        "data_sets[0][['tx_pwr','rssi_5']],\n",
        "data_sets[1][['tx_pwr','rssi_1']],\n",
        "data_sets[1][['tx_pwr','rssi_2']],\n",
        "data_sets[1][['tx_pwr','rssi_3']],\n",
        "data_sets[1][['tx_pwr','rssi_4']],\n",
        "data_sets[1][['tx_pwr','rssi_5']],\n",
        "data_sets[1][['tx_pwr','rssi_1']]]\n"
      ],
      "metadata": {
        "id": "wIgd2EyhZj6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling the dataset\n",
        "def scale_dataset(df_ip):\n",
        "  scaler = MinMaxScaler()\n",
        "  return [scaler, scaler.fit_transform(df_ip)]\n",
        "scaler_set = []\n",
        "data_scaled = []\n",
        "for df in df_input:\n",
        "  scaler, data = scale_dataset(df)\n",
        "  scaler_set.append(scaler)\n",
        "  data_scaled.append(data)"
      ],
      "metadata": {
        "id": "_ImzpooRa37K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(scaled_data):\n",
        "  features = scaled_data\n",
        "  target = scaled_data[:,1]\n",
        "  return [features, target]"
      ],
      "metadata": {
        "id": "cduOh5sHb4Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_target_set = []\n",
        "for data in data_scaled:\n",
        "  feature_target_set.append(get_features(data))"
      ],
      "metadata": {
        "id": "uUB7ABeucKX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(features, target):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, random_state=123, shuffle=False)\n",
        "  x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state=123, shuffle=False)\n",
        "  return [x_train, y_train, x_test, y_test, x_val, y_val]"
      ],
      "metadata": {
        "id": "t-Vp8yyWe70z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = []\n",
        "test_set = []\n",
        "validation_set = []\n",
        "for data in feature_target_set:\n",
        "  result = split_dataset(data[0], data[1])\n",
        "  train_set.append([result[0],result[1]])\n",
        "  test_set.append([result[2],result[3]])\n",
        "  validation_set.append([result[4],result[5]])"
      ],
      "metadata": {
        "id": "fymGyPsMfsx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_length = 5\n",
        "batch_size = 32\n",
        "num_features = 2"
      ],
      "metadata": {
        "id": "NJQF_SrlofHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(x,y):\n",
        "  return TimeseriesGenerator(x,y, length = window_length, sampling_rate=1, batch_size=batch_size)\n",
        "  "
      ],
      "metadata": {
        "id": "gIiebMAdg8rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = []\n",
        "test_generator = []\n",
        "val_generator = []\n",
        "for train in train_set:\n",
        "  train_generator.append(generator(train[0],train[1]))\n",
        "for test in test_set:\n",
        "  test_generator.append(generator(test[0],test[1]))\n",
        "for val in validation_set:\n",
        "  val_generator.append(generator(val[0],val[1]))"
      ],
      "metadata": {
        "id": "y3RQVTnphnw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(128,input_shape=(window_length, num_features),return_sequences=True))\n",
        "model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n",
        "model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
        "model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.LSTM(64, return_sequences=False))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(1))"
      ],
      "metadata": {
        "id": "-7tVYFLUib3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "mkFI8y3iimEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_gen, val_gen):\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,mode='min')\n",
        "  model.compile(loss=tf.losses.MeanSquaredError(), optimizer=tf.optimizers.Adam(), metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "  history = model.fit_generator(train_gen, epochs=100,\n",
        "                              validation_data=val_gen,\n",
        "                              shuffle=False,\n",
        "                              callbacks=[early_stopping])\n",
        "  return [model,history]"
      ],
      "metadata": {
        "id": "XOEqCGG7jK68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_plot(history):\n",
        "  plt.plot(history.history['loss'],label='Training Loss')\n",
        "  plt.plot(history.history['val_loss'],label='Validation loss')\n",
        "  plt.title(f\"model_{i+1} Tx = {10 + i}\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "HCjJrRvAj0oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(test_gen, model):\n",
        "  return model.evaluate_generator(test_gen, verbose = 0)"
      ],
      "metadata": {
        "id": "7fgfnFwjnNkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(model, test_gen):\n",
        "  return model.predict_generator(test_gen)"
      ],
      "metadata": {
        "id": "6Lsz_Pxwnqbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def actual_pred(predictions, x_test, df_input, scaler, i):\n",
        "  df_pred = pd.concat([pd.DataFrame(x_test[:,:-1][window_length:]),pd.DataFrame(predictions)],axis=1)\n",
        "  reverse_trans = scaler.inverse_transform(df_pred)\n",
        "  df_final = df_input[-predictions.shape[0]:]\n",
        "  df_final['pred'] = reverse_trans[:,-1]\n",
        "  df_final[[f'rssi_{(i % 5) + 1}','pred']].plot(figsize=(10,8))\n",
        "  plt.title(f\"model_{i+1} Tx = {10+i}\")\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uhB4LNmIoMqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "models = []\n",
        "histories = []\n",
        "evaluations = []\n",
        "predictions  = []\n",
        "for i in range(11):\n",
        "  model, history = train_model(train_generator[i],val_generator[i])\n",
        "  models.append(model)\n",
        "  histories.append(history)\n",
        "  evaluations.append(evaluate(test_generator[i],model))\n",
        "  prediction = make_prediction(model, test_generator[i])\n",
        "  predictions.append(prediction)\n",
        "  file_name = f'saved_model_{10+i}.pkl'\n",
        "  pickle.dump(model, open(file_name, 'wb'))\n",
        "\n"
      ],
      "metadata": {
        "id": "VNeEvsgp0hmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(11):\n",
        "  train_val_plot(histories[i])"
      ],
      "metadata": {
        "id": "jO7trKFJ2jKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(11):\n",
        "  actual_pred(predictions[i], test_set[i][0], df_input[i], scaler_set[i], i)  "
      ],
      "metadata": {
        "id": "IznXEHjVr-tU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}